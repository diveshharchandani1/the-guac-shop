# **The Guac Stop: End-to-End Data Warehousing and Analytics Solution**

## **Overview**
This project showcases a comprehensive **data warehousing and analytics solution** designed for **The Guac Stop**, leveraging industry-standard tools and cloud services to streamline **data ingestion, transformation, and visualization**. The goal was to create an efficient and scalable **data pipeline** that enables real-time insights and decision-making.

### **Tech Stack**
- ğŸ“‚ **Oracle Cloud** â€“ Data warehouse hosting and management  
- ğŸ”„ **Apache Hop** â€“ ETL pipeline design and orchestration  
- ğŸ“ˆ **Tableau** â€“ Data visualization and dashboard development  

## **Project Workflow**
### **1ï¸âƒ£ Setting Up the Cloud Data Warehouse**
- Configured a cloud-based data warehousing environment using **Oracle Cloud**.
- Built **dimension and fact tables** using **SQL DDL statements** to define relationships and enforce data integrity.
- Addressed key architectural considerations:
  - âœ… **Date Dimension Enhancement** â€“ Implemented dynamic date structures for efficient time management.
  - âœ… **Fact Table Relationships** â€“ Ensured a **star schema** design by linking fact tables only through shared dimensions.

#### ğŸ“Œ **Dimensional Model**
*(Insert an image of your dimensional model here)*
```md
![Dimensional Model](images/dimensional_model.png)
```

---

### **2ï¸âƒ£ Creating the ETL Pipeline with Apache Hop**
- Designed an **ETL pipeline** to populate the data warehouse.
- **Key challenges and solutions:**
  - âš ï¸ **Reserved Keywords** â€“ Renamed the `Date` column in the `Date_Dim` table to avoid conflicts in Oracle SQL.
  - ğŸ› ï¸ **Schema Consistency** â€“ Identified and corrected missing attributes (e.g., `ProductKey` in the `Product` table).
  - ğŸ”— **Foreign Key Handling** â€“ Managed relationships through **ETL mappings** instead of database constraints for flexibility.

#### ğŸ“Œ **ETL Pipeline Flow**
*(Insert an image of your Apache Hop ETL pipeline here)*
```md
![ETL Pipeline Flow](images/etl_pipeline.png)
```

---

### **3ï¸âƒ£ Building the Business Intelligence Dashboard**
- Developed an **interactive dashboard in Tableau** to visualize sales performance.
- **Dashboard Features:**
  - ğŸ“Š **Total Sales KPI** â€“ Aggregated key performance indicators (KPIs) for quick insights.
  - ğŸ“‰ **Sales by Brand & Category** â€“ Breakdown of sales performance across different product segments.
  - ğŸ“† **Month-over-Month Trends** â€“ Analyzed sales trends and seasonality.
  - ğŸ›ï¸ **Filters** â€“ Enabled city and category-based data exploration.

#### ğŸ“Œ **Dashboard Screenshot**
*(Insert an image of your Tableau dashboard here)*
```md
![Dashboard Screenshot](images/dashboard.png)
```

---

## **Key Takeaways**
- âœ… **Data Integrity**: Ensured consistency through structured **SQL relationships**.  
- ğŸš€ **ETL Optimization**: Leveraged **Apache Hop** to streamline data transformation and improve efficiency.  
- ğŸ“Š **Visual Analytics**: Used **Tableau** to make complex data more accessible for business users.  

## **Repository Structure**
```md
â”œâ”€â”€ data/                    # Sample data files and SQL scripts
â”œâ”€â”€ etl/                     # Apache Hop ETL pipeline files
â”œâ”€â”€ dashboard/               # Tableau workbook and screenshots
â”œâ”€â”€ README.md                # Project documentation (this file)
```

## **Next Steps**
- Automate ETL pipeline for **real-time data ingestion**.
- Expand dataset to include **customer behavior insights**.
- Optimize **dashboard performance** for large datasets.

## **Author**
ğŸ‘¨â€ğŸ’» **Divesh Harchandani**  
ğŸ“§ [Your Email]  
ğŸ”— [LinkedIn Profile]  
ğŸš€ **University at Buffalo | Business & Entrepreneur Partnerships**  

